{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47d3e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pathlib as pl\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_vectorized_data(data_root, dataset_type='train'):\n",
    "    \"\"\"\n",
    "    Загружает векторизованные данные из TSV-файлов\n",
    "    \n",
    "    Args:\n",
    "        data_root (str): Путь к корневой директории с данными\n",
    "        dataset_type (str): Тип набора ('train' или 'test')\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (векторы, метки) как numpy массивы\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset_path = pl.Path(data_root) / dataset_type\n",
    "    \n",
    "    if not dataset_path.exists():\n",
    "        raise FileNotFoundError(f\"Директория {dataset_path} не найдена\")\n",
    "    \n",
    "    # Собираем все файлы .tsv из подкаталогов\n",
    "    tsv_files = list(dataset_path.glob('*/*.tsv'))\n",
    "    \n",
    "    vectors = []\n",
    "    labels = []\n",
    "    \n",
    "    for tsv_file in tsv_files:\n",
    "        try:\n",
    "            # Получаем метку класса из имени родительской папки\n",
    "            class_label = int(tsv_file.parent.name)\n",
    "            \n",
    "            with tsv_file.open('r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split('\\t')\n",
    "                    \n",
    "                    if len(parts) != 101:  # 1 колонка ID + 100 значений вектора\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        vector = [float(x) for x in parts[1:101]]\n",
    "                        if len(vector) == 100:\n",
    "                            vectors.append(vector)\n",
    "                            labels.append(class_label)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обработке файла {tsv_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return np.array(vectors), np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "799e9e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено 120000 тренировочных образцов\n",
      "Загружено 7600 тестовых образцов\n"
     ]
    }
   ],
   "source": [
    "# Пути к данным (укажите свой правильный путь)\n",
    "base_path = 'C:/Users/alex4/Desktop/code/lab1/annotated-corpus-vectorized'\n",
    "\n",
    "# Загрузка данных\n",
    "X_train, y_train = load_vectorized_data(base_path, 'train')\n",
    "X_test, y_test = load_vectorized_data(base_path, 'test')\n",
    "\n",
    "print(f\"Загружено {len(X_train)} тренировочных образцов\")\n",
    "print(f\"Загружено {len(X_test)} тестовых образцов\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16fff05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Вычисление метрик precision, recall, f1-score, accuracy.\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.array): Истинные метки классов\n",
    "        y_pred (np.array): Предсказанные метки классов\n",
    "        \n",
    "    Returns:\n",
    "        dict: Словарь с метками precision, recall, f1-score и accuracy\n",
    "    \"\"\"\n",
    "    # Число классов\n",
    "    classes = np.unique(y_true)\n",
    "    \n",
    "    # Инициализируем метрики\n",
    "    precision = {}\n",
    "    recall = {}\n",
    "    f1 = {}\n",
    "    accuracy = 0\n",
    "    \n",
    "    # Рассчитываем точность (precision), полноту (recall) и f1-score\n",
    "    for cls in classes:\n",
    "        tp = np.sum((y_true == cls) & (y_pred == cls))  # True Positives\n",
    "        fn = np.sum((y_true == cls) & (y_pred != cls))  # False Negatives\n",
    "        fp = np.sum((y_true != cls) & (y_pred == cls))  # False Positives\n",
    "        tn = np.sum((y_true != cls) & (y_pred != cls))  # True Negatives\n",
    "        \n",
    "        precision[cls] = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall[cls] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1[cls] = 2 * precision[cls] * recall[cls] / (precision[cls] + recall[cls]) if (precision[cls] + recall[cls]) > 0 else 0\n",
    "        \n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "       # Среднее значение по всем классам для f1, precision и recall\n",
    "    avg_precision = np.mean(list(precision.values()))\n",
    "    avg_recall = np.mean(list(recall.values()))\n",
    "    avg_f1 = np.mean(list(f1.values()))\n",
    "    \n",
    "    return {\n",
    "        'precision': avg_precision,\n",
    "        'recall': avg_recall,\n",
    "        'f1_score': avg_f1,\n",
    "        'accuracy': accuracy\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee878894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM with linear kernel...\n"
     ]
    }
   ],
   "source": [
    "# Функция для обучения модели SVM с разными ядрами и сравнения с MLP\n",
    "def train_and_evaluate_models(X_train, y_train, X_test, y_test, kernels=['linear', 'rbf'], epochs=5):\n",
    "    results = {}\n",
    "    \n",
    "    for kernel in kernels:\n",
    "        print(f\"Training SVM with {kernel} kernel...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Обучение модели SVM с выбранным ядром\n",
    "        svm_model = SVC(kernel=kernel, max_iter=10000)  # Установим max_iter, чтобы избежать проблемы с большим числом итераций\n",
    "        svm_model.fit(X_train, y_train)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        \n",
    "        # Прогнозируем на тестовых данных\n",
    "        y_pred_svm = svm_model.predict(X_test)\n",
    "        \n",
    "        # Считаем метрики для SVM\n",
    "        svm_metrics = calculate_metrics(y_test, y_pred_svm)\n",
    "        svm_metrics['training_time'] = training_time\n",
    "        results[f\"SVM_{kernel}\"] = svm_metrics\n",
    "        \n",
    "        print(f\"SVM {kernel} - accuracy: {svm_metrics['accuracy']:.4f}, F1-score: {svm_metrics['f1_score']:.4f}\")\n",
    "        \n",
    "    # Эксперимент с MLP\n",
    "    print(f\"Training MLP...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Обучение MLP модели\n",
    "    mlp_model = MLPClassifier(max_iter=epochs)\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    training_time_mlp = end_time - start_time\n",
    "    \n",
    "    # Прогнозируем на тестовых данных\n",
    "    y_pred_mlp = mlp_model.predict(X_test)\n",
    "    \n",
    "    # Считаем метрики для MLP\n",
    "    mlp_metrics = calculate_metrics(y_test, y_pred_mlp)\n",
    "    mlp_metrics['training_time'] = training_time_mlp\n",
    "    results['MLP'] = mlp_metrics\n",
    "    \n",
    "    print(f\"MLP - accuracy: {mlp_metrics['accuracy']:.4f}, F1-score: {mlp_metrics['f1_score']:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Пример использования\n",
    "# Данные уже загружены в X_train, y_train, X_test, y_test\n",
    "\n",
    "# Количество эпох для обучения MLP\n",
    "epochs = 10\n",
    "\n",
    "# Ядра для SVM\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "\n",
    "# Проведение экспериментов\n",
    "results = train_and_evaluate_models(X_train, y_train, X_test, y_test, kernels=kernels, epochs=epochs)\n",
    "\n",
    "# Вывод результатов\n",
    "for model, metrics in results.items():\n",
    "    print(f\"\\nModel: {model}\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1-score: {metrics['f1_score']:.4f}\")\n",
    "    print(f\"Training Time: {metrics['training_time']:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
